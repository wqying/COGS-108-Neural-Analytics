{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries for data analysis\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")  # read the downloaded house pricing dataset\n",
    "data_array = data.values  # converts the data to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2014-05-02 00:00:00', 313000.0, 3.0, 1.5, 1340, 7912, 1.5, 0, 0,\n",
       "       3, 1340, 0, 1955, 2005, '18810 Densmore Ave N', 'Shoreline',\n",
       "       'WA 98133', 'USA'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array[0, :]  # takes the first row and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2014-05-02 00:00:00' 313000.0 3.0 ... 'Algona' 'WA 98133' 'USA']\n",
      " ['2014-05-02 00:00:00' 2384000.0 5.0 ... 'Algona' 'WA 98119' 'USA']\n",
      " ['2014-05-02 00:00:00' 342000.0 3.0 ... 'Algona' 'WA 98042' 'USA']\n",
      " ...\n",
      " ['2014-07-09 00:00:00' 416904.166667 3.0 ... 'Yarrow Point' 'WA 98059'\n",
      "  'USA']\n",
      " ['2014-07-10 00:00:00' 203400.0 4.0 ... 'Yarrow Point' 'WA 98178' 'USA']\n",
      " ['2014-07-10 00:00:00' 220600.0 3.0 ... 'Yarrow Point' 'WA 98042' 'USA']]\n"
     ]
    }
   ],
   "source": [
    "print(data_array)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Algona': 801800.0, 'Auburn': 534110.0170454546, 'Beaux Arts Village': 460000.0, 'Bellevue': 547642.8671328671, 'Black Diamond': 658521.7777777778, 'Bothell': 605654.5454545454, 'Burien': 620418.3513513514, 'Carnation': 584318.1818181818, 'Clyde Hill': 604281.8181818182, 'Covington': 519212.72093023255, 'Des Moines': 495751.8620689655, 'Duvall': 532396.4285714285, 'Enumclaw': 501099.10714285716, 'Fall City': 432554.54545454547, 'Federal Way': 488781.7162162162, 'Inglewood-Finn Hill': 575000.0, 'Issaquah': 538765.192513369, 'Kenmore': 531811.2121212122, 'Kent': 543724.4216216216, 'Kirkland': 565727.2887700534, 'Lake Forest Park': 571415.8333333334, 'Maple Valley': 658111.34375, 'Medina': 458500.0, 'Mercer Island': 504918.43023255817, 'Milton': 586500.0, 'Newcastle': 449671.63636363635, 'Normandy Park': 594696.5555555555, 'North Bend': 545364.3, 'Pacific': 313750.0, 'Preston': 1180000.0, 'Ravensdale': 491492.85714285716, 'Redmond': 552138.2553191489, 'Renton': 565560.0068259386, 'Sammamish': 556591.5771428571, 'SeaTac': 439269.275862069, 'Seattle': 568060.4837889384, 'Shoreline': 673637.1788617886, 'Skykomish': 9659300.0, 'Snoqualmie': 246821.32303160566, 'Snoqualmie Pass': 127160.0, 'Tukwila': 366018.84770986205, 'Vashon': 409434.90409586206, 'Woodinville': 337698.6238189131, 'Yarrow Point': 343809.375}\n"
     ]
    }
   ],
   "source": [
    "# find the average price in each city:\n",
    "cities = data_array[:, -3]  # specify that I only want the cities from the columns, and all rows\n",
    "prices = data_array[:, 1]\n",
    "sorted_indices = np.argsort(cities)  # sort by indeces by cities\n",
    "\n",
    "cities_sorted = cities[sorted_indices]\n",
    "prices_sorted = prices[sorted_indices]\n",
    "\n",
    "# clump the city names and their relative prices together\n",
    "sorted_data = np.column_stack((cities_sorted, prices_sorted))\n",
    "\n",
    "# get the unique city names\n",
    "unique_city_names = np.unique(sorted_data[:, 0])\n",
    "\n",
    "average_prices = {}  # dictionary for key value pair: city and average price\n",
    "\n",
    "for city in unique_city_names:\n",
    "    # filter prices for the current city\n",
    "    city_prices = prices_sorted[cities_sorted == city]\n",
    "    average_prices[city] = float(np.mean(city_prices))\n",
    "    # ^ the float here is to remove weird printed syntax\n",
    "\n",
    "print(average_prices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the nilearn library\n",
    "from nilearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added README.md to /Users/qianyingwong/nilearn_data\n",
      "\n",
      "\n",
      "Dataset created in /Users/qianyingwong/nilearn_data/haxby2001\n",
      "\n",
      "Downloading data from https://www.nitrc.org/frs/download.php/7868/mask.nii.gz ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (0 seconds, 0 min)\n",
      " ...done. (0 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://data.pymvpa.org/datasets/haxby2001/MD5SUMS ...\n",
      "Downloading data from http://data.pymvpa.org/datasets/haxby2001/subj1-2010.01.14.tar.gz ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 304365568 of 314803244 bytes (96.7%,    0.8s remaining) ...done. (24 seconds, 0 min)\n",
      "Extracting data from /Users/qianyingwong/nilearn_data/haxby2001/b6297e3e4eedbdbfb999e3188d364506/subj1-2010.01.14.tar.gz..... done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://data.pymvpa.org/datasets/haxby2001/subj2-2010.01.14.tar.gz ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 280756224 of 291168628 bytes (96.4%,    0.7s remaining) ...done. (20 seconds, 0 min)\n",
      "Extracting data from /Users/qianyingwong/nilearn_data/haxby2001/b6297e3e4eedbdbfb999e3188d364506/subj2-2010.01.14.tar.gz..... done.\n"
     ]
    }
   ],
   "source": [
    "# Using the haxby dataset would be a great advantage in the group project!\n",
    "data = datasets.fetch_haxby(\n",
    "    data_dir = None,\n",
    "    subjects = 2,\n",
    "    fetch_stimuli = False\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
